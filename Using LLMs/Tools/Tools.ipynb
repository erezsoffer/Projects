{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z38HDIdQSCKf",
        "outputId": "0f732766-cafb-41ee-a136-2b0693e6d021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/328.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.14\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSsRXN5bL2NT",
        "outputId": "1cd85bbb-deda-40ca-fd7d-2e38bc41322a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting duckduckgo_search\n",
            "  Downloading duckduckgo_search-6.2.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search) (8.1.7)\n",
            "Collecting pyreqwest-impersonate>=0.5.0 (from duckduckgo_search)\n",
            "  Downloading pyreqwest_impersonate-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreqwest-impersonate, duckduckgo_search\n",
            "Successfully installed duckduckgo_search-6.2.1 pyreqwest-impersonate-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install duckduckgo_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzw6o4OUfArL",
        "outputId": "53c04fb6-4cfa-4c67-fbf8-e491db7e57a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average grade has been calculated and stored in 'query3.json'\n",
            "The Python program to calculate the average grade has been successfully executed. The average grade has been calculated as 85.00625 and the result has been stored in 'query3.json'.\n"
          ]
        }
      ],
      "source": [
        "from openai import AzureOpenAI\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "# Set up Azure OpenAI Service credentials\n",
        "client = AzureOpenAI(\n",
        "    api_key='api_key',  # Replace with your api_key\n",
        "    api_version='2024-02-01',\n",
        "    azure_endpoint='azure_endpoint'  # Replace with your azure_endpoint\n",
        ")\n",
        "\n",
        "# Function to extract entities from a file using LLM\n",
        "def extract_entities_from_file(file_name: str, entity_type: str) -> str:\n",
        "    with open(file_name, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Prompt to extract entities of a specific type from the content\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Extract all entities of the type '{entity_type}' from the following text:\n",
        "{content}\n",
        "Return only the entities as a JSON list.\n",
        "\"\"\"\n",
        "\n",
        "    # Send request to Azure OpenAI Service\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt4\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract entities from response\n",
        "    entities = response.choices[0].message.content\n",
        "    return entities\n",
        "\n",
        "# Function to perform an internet search using DuckDuckGo Instant Answer API and LLM\n",
        "def internet_search_attribute(a_entity: str, a_attribute: str) -> str:\n",
        "    # Perform search query using DuckDuckGo\n",
        "    query = f\"what is {a_entity}'s {a_attribute}?\"\n",
        "    results = list(DDGS().text(query, max_results=1))\n",
        "\n",
        "    if not results:\n",
        "        return json.dumps({a_entity: {a_attribute: \"No results found\"}})\n",
        "\n",
        "    search_result = results[0][\"body\"]\n",
        "\n",
        "    # Prompt to extract the attribute from the search result\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Based on the search result below, provide the {a_attribute} of {a_entity}:\n",
        "Search result: {search_result}\n",
        "Return the result as a JSON structure of the form: {{\"a_entity\": {a_entity}, \"{a_attribute}\": Answer}}\n",
        "\"\"\"\n",
        "\n",
        "    # Send request to Azure OpenAI Service\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt4\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract answer from response\n",
        "    answer = response.choices[0].message.content\n",
        "    return answer\n",
        "\n",
        "# Function to generate a Python program for data analysis using LLM\n",
        "def generate_analysis_program(analysis_request: str, input_file: str, columns: str, row_example: str, output_file: str) -> str:\n",
        "    # Prompt to generate a Python program for analyzing a CSV file\n",
        "    prompt = f\"\"\"\n",
        "I need to generate a Python program to analyze a CSV file. Here are the details:\n",
        "- Analysis request: {analysis_request}\n",
        "- Input file: {input_file}\n",
        "- Columns: {columns}\n",
        "- Example row: {row_example}\n",
        "- Output file: {output_file}\n",
        "\n",
        "Please generate the Python code for this analysis. The program should read the CSV file, perform the analysis based on the request, and write the output as a JSON object to the output file.\n",
        "\"\"\"\n",
        "\n",
        "    # Send request to Azure OpenAI Service\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt4\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract generated code from response\n",
        "    generated_code = response.choices[0].message.content\n",
        "    return clean_code(generated_code)\n",
        "\n",
        "# Function to clean the generated code by extracting the code block\n",
        "def clean_code(content):\n",
        "    # Extract content between ```python and ``` markers\n",
        "    try:\n",
        "        # Splitting content to capture only the code between the specific markers\n",
        "        start_code = content.index(\"```python\") + len(\"```python\")\n",
        "        end_code = content.index(\"```\", start_code)\n",
        "        content = content[start_code:end_code].strip()\n",
        "    except ValueError:\n",
        "        \"There was an error. Please try again\"\n",
        "    return content\n",
        "\n",
        "# Function to execute a Python program\n",
        "def execute_python_program(program_fn: str, output_fn: str) -> str:\n",
        "    try:\n",
        "        # Execute the Python program\n",
        "        exec(open(program_fn).read())\n",
        "        with open(output_fn, 'r') as file:\n",
        "            return file.read()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Function to write content to a file\n",
        "def write_file(file_content: str, fn: str):\n",
        "    # Write the content to the specified file\n",
        "    with open(fn, \"w\") as file:\n",
        "        file.write(file_content)\n",
        "    return f\"File content was successfully written to {fn}\"\n",
        "\n",
        "# Agent loop to process the input JSON and handle function calls\n",
        "def agent_loop(input_json):\n",
        "    query_file = input_json[\"query_name\"]\n",
        "    log_file = f\"log_{query_file.split('.')[0]}.txt\"\n",
        "    llm_call_count = 0\n",
        "    function_call_count = 0\n",
        "    LLM_CALL_LIMIT = 10\n",
        "    FUNCTION_CALL_LIMIT = 10\n",
        "\n",
        "    with open(log_file, \"w\") as log:\n",
        "\n",
        "        resources = input_json[\"file_resources\"]\n",
        "\n",
        "        with open(query_file, \"r\") as file:\n",
        "            query = file.read()\n",
        "\n",
        "        messages = [{\"role\": \"user\", \"content\": f\"{query}\\n resources:{resources}\"}]\n",
        "\n",
        "        # Define available functions for the agent\n",
        "        functions = [\n",
        "            {\n",
        "                \"name\": \"extract_entities_from_file\",\n",
        "                \"description\": \"Extract entities from a text file\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"file_name\": {\"type\": \"string\"},\n",
        "                        \"entity_type\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                    \"required\": [\"file_name\", \"entity_type\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"internet_search_attribute\",\n",
        "                \"description\": \"Search the internet for an attribute of an entity\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"a_entity\": {\"type\": \"string\"},\n",
        "                        \"a_attribute\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                    \"required\": [\"a_entity\", \"a_attribute\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"generate_analysis_program\",\n",
        "                \"description\": \"Generate a Python program to analyze a CSV file\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"analysis_request\": {\"type\": \"string\"},\n",
        "                        \"input_file\": {\"type\": \"string\"},\n",
        "                        \"columns\": {\"type\": \"string\"},\n",
        "                        \"row_example\": {\"type\": \"string\"},\n",
        "                        \"output_file\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                    \"required\": [\"analysis_request\", \"input_file\", \"columns\", \"row_example\", \"output_file\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"execute_python_program\",\n",
        "                \"description\": \"Execute a Python program\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"program_fn\": {\"type\": \"string\"},\n",
        "                        \"output_fn\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                    \"required\": [\"program_fn\", \"output_fn\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"write_file\",\n",
        "                \"description\": \"Write content to a file\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"file_content\": {\"type\": \"string\"},\n",
        "                        \"fn\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                    \"required\": [\"file_content\", \"fn\"]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Function to call the appropriate function based on the function name\n",
        "        def call_function(function_name, arguments):\n",
        "            nonlocal function_call_count\n",
        "            function_call_count += 1\n",
        "\n",
        "            if function_call_count > FUNCTION_CALL_LIMIT:\n",
        "                return \"Function call limit exceeded\"\n",
        "\n",
        "            if function_name == \"extract_entities_from_file\":\n",
        "                return extract_entities_from_file(**arguments)\n",
        "            elif function_name == \"internet_search_attribute\":\n",
        "                return internet_search_attribute(**arguments)\n",
        "            elif function_name == \"generate_analysis_program\":\n",
        "                return generate_analysis_program(**arguments)\n",
        "            elif function_name == \"execute_python_program\":\n",
        "                return execute_python_program(**arguments)\n",
        "            elif function_name == \"write_file\":\n",
        "                return write_file(**arguments)\n",
        "\n",
        "        # Loop to process the input and handle function calls\n",
        "        while True:\n",
        "            if llm_call_count >= LLM_CALL_LIMIT or function_call_count >= FUNCTION_CALL_LIMIT:\n",
        "                final_response = {\n",
        "                    \"error\": \"LLM or function call limit exceeded\",\n",
        "                    \"llm_calls\": llm_call_count,\n",
        "                    \"function_calls\": function_call_count\n",
        "                }\n",
        "                break\n",
        "\n",
        "            # Send request to Azure OpenAI Service\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt4\",\n",
        "                messages=messages,\n",
        "                functions=functions,\n",
        "                function_call=\"auto\"\n",
        "            )\n",
        "\n",
        "            llm_call_count += 1\n",
        "\n",
        "            response_message = response.choices[0].message\n",
        "            function_call = response_message.function_call\n",
        "\n",
        "            if function_call:\n",
        "                function_name = function_call.name\n",
        "                function_args = json.loads(function_call.arguments)\n",
        "\n",
        "                log.write(f\"**Entering agent {function_name}**\\n\")\n",
        "                for arg_name, arg_value in function_args.items():\n",
        "                    value_to_log = arg_value[:50] if isinstance(arg_value, str) else str(arg_value)\n",
        "                    log.write(f\"Parameter {arg_name} = {value_to_log}\\n\")\n",
        "\n",
        "                function_response = call_function(function_name, function_args)\n",
        "\n",
        "                log.write(f\"**Leaving agent {function_name}**\\n\")\n",
        "\n",
        "                messages.append({\n",
        "                    \"role\": \"function\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                })\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        final_response = response.choices[0].message.content\n",
        "        return final_response\n",
        "\n",
        "# Input JSON\n",
        "input_json_file = 'input.json'\n",
        "with open(input_json_file, 'r') as f:\n",
        "    input_json = json.load(f)\n",
        "\n",
        "result = agent_loop(input_json)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfzvNBKQ4U4H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
